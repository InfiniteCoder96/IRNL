{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pasin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np                                                                \n",
    "import nltk                                      \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords                                \n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv\"\n",
    "original_data=pd.read_csv(url,error_bad_lines=False,sep='\\t') #loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.isnull().values.sum() #Check if there are any `null` values in the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = original_data.dropna() #Drop the three null values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404287, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = original_data.copy() #copy original_data to new variable because to resue orginal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              149263\n",
      "qid1            149263\n",
      "qid2            149263\n",
      "question1       149263\n",
      "question2       149263\n",
      "is_duplicate    149263\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (data[data.is_duplicate == 1].count()) #checking balance of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#this dataset doesn't have data imbalancing issue, since both the classes have\n",
    "#if not equal but fair amount of records in each class. The class label 0 has\n",
    "#around 250K records whereas class label 1 has around 150K records.\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.gca()\n",
    "data['is_duplicate'].hist(ax=ax)\n",
    "plt.xlabel('is_duplicate',fontsize=20)\n",
    "plt.ylabel('questions',fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.title('Labels vs. Questions Plot',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'again', \"wouldn't\", 'into', 'd', 'shan', 'be', 'than', 'isn', 'wouldn', 'been', 'which', 'when', 'ma', 'being', 'whom', 'was', 'they', 'from', 'now', \"won't\", 'her', 're', 'is', 'an', 'for', 'it', 'm', 'out', 'did', 'the', 'at', 'all', 'those', 'themselves', 'about', 'you', 'too', 'having', \"you'll\", \"you've\", 'yourself', \"doesn't\", \"needn't\", 'during', 'off', 'will', 'against', 'below', 'and', 'a', 'has', 'him', 'shouldn', 'am', 'but', 'if', 'before', 'then', 'mightn', 'its', 'needn', 'once', 'ours', 'these', 'hadn', 'so', \"couldn't\", 'she', 'up', \"haven't\", 'no', 'ourselves', 'yourselves', 'or', 'were', 'further', 'have', 'more', 'just', 'won', 'while', 'by', 'to', 'why', 'itself', 'in', 'through', 'y', \"that'll\", 'your', 'aren', 'who', 'ain', 'here', \"should've\", 'are', 'their', \"weren't\", 'doesn', \"you'd\", 'do', 'where', \"hadn't\", 'hers', 'himself', 'them', 'few', 'should', 'll', 'such', \"mightn't\", 'he', 'i', 'theirs', 'after', 'on', 'nor', 'how', \"wasn't\", 'very', 'his', 'my', 'above', 'most', 'can', 'each', 'own', 'o', 't', 'only', 'of', \"didn't\", 'haven', \"you're\", 'that', 'because', 'we', 'other', 'yours', 'this', 'what', \"she's\", 'over', \"aren't\", 'hasn', 'didn', \"isn't\", 'does', 'weren', 'down', 've', 'myself', 'until', 'herself', \"shouldn't\", 'with', 'as', \"shan't\", \"don't\", \"mustn't\", 'our', 'had', \"hasn't\", 'wasn', 'don', 'between', 'there', 'couldn', \"it's\", 'under', 'some', 'me', 'any', 'same', 's', 'not', 'mustn', 'doing', 'both'}\n"
     ]
    }
   ],
   "source": [
    "stop = set(stopwords.words('english')) #stopwords that are there in the `nltk` library which will be removed from the dataset.\n",
    "print(stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I defined `sentence_to_wordlist` which takes each sentence from one of the two columns `question1` and `question2`. On each sentence it applies beautifulsoup for removing html tags if any. Then on that string I applied `regular expression` for some text preprocessing like include upper and lower case alphabets, 0-9 numbers, correct short forms and so on.\n",
    "Then applied `.lower()` to bring everything to lowercase to maintain regularity in every word and `.split()` method to convert the sentence into list of words. Finally, on these list of words I iterated one by one to check if that word is not a `stopword` if not then it is returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_wordlist(sentence):\n",
    "    \n",
    "    \n",
    "    sentence = BeautifulSoup(sentence)  \n",
    "    sentence = sentence.get_text()\n",
    "\n",
    "    sentence = re.sub(r\"[^A-Za-z%@#$&*]\", \" \", sentence)\n",
    "    sentence = re.sub(r\"what's\", \"what is \", sentence)\n",
    "    sentence = re.sub(r\"\\'s\", \" \", sentence)\n",
    "    sentence = re.sub(r\"\\'ve\", \" have \", sentence)\n",
    "    sentence = re.sub(r\"can't\", \"cannot \", sentence)\n",
    "    sentence = re.sub(r\"n't\", \" not \", sentence)\n",
    "    sentence = re.sub(r\"i'm\", \"i am \", sentence)\n",
    "    sentence = re.sub(r\"\\'re\", \" are \", sentence)\n",
    "    sentence = re.sub(r\"\\'d\", \" would \", sentence)\n",
    "    sentence = re.sub(r\"\\'ll\", \" will \", sentence)\n",
    "    sentence = re.sub(r\",\", \" \", sentence)\n",
    "    sentence = re.sub(r\"\\.\", \" \", sentence)\n",
    "    sentence = re.sub(r\"\\/\", \" \", sentence)\n",
    "    sentence = re.sub(r\"\\^\", \" ^ \", sentence)\n",
    "    sentence = re.sub(r\"\\+\", \" + \", sentence)\n",
    "    sentence = re.sub(r\"\\=\", \" = \", sentence)\n",
    "    sentence = re.sub(r\"'\", \" \", sentence)\n",
    "    sentence = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", sentence)\n",
    "    sentence = re.sub(r\":\", \" : \", sentence)\n",
    "    sentence = re.sub(r\" e g \", \" eg \", sentence)\n",
    "    sentence = re.sub(r\" b g \", \" bg \", sentence)\n",
    "    sentence = re.sub(r\" u s \", \" american \", sentence)\n",
    "    sentence = re.sub(r\"\\0s\", \"0\", sentence)\n",
    "    sentence = re.sub(r\"e - mail\", \"email\", sentence)\n",
    "    sentence = re.sub(r\"j k\", \"jk\", sentence)\n",
    "    sentence = re.sub(r\"\\s{2,}\", \" \", sentence)\n",
    "    \n",
    "    sentence = sentence.lower().split()\n",
    "\n",
    "\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    sentence = [w for w in sentence if not w in stops]\n",
    "\n",
    "    return(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['question1', 'question2'] #Below are the stopwords that are there in the `nltk` library which will be removed from the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I iterated over each row by using dataframes function called `iterrows()` which iterates over each record or row of the dataframe. For each row I iterated over the two columns namely `question1`, `question2` and then for each record I called the `sentence_to_wordlist()` function passing in the row and one of the two columns. Using pandas `at()` function I updated for each row both columns `question1` and `question2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\bs4\\__init__.py:333: MarkupResemblesLocatorWarning: \".\" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    }
   ],
   "source": [
    "for indices, record in data.iterrows():\n",
    "        # Iterate through the text of both questions of the row\n",
    "        for column in columns:\n",
    "            data.at[indices, column] =  sentence_to_wordlist(record[column])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I print the first few rows of the modified dataframe and we can see that both the `question1` and `question2` columns have been converted into list of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[step, step, guide, invest, share, market, india]</td>\n",
       "      <td>[step, step, guide, invest, share, market]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[story, kohinoor, koh, noor, diamond]</td>\n",
       "      <td>[would, happen, indian, government, stole, koh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>[increase, speed, internet, connection, using,...</td>\n",
       "      <td>[internet, speed, increased, hacking, dns]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[mentally, lonely, solve]</td>\n",
       "      <td>[find, remainder, math, math, divided]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>[one, dissolve, water, quikly, sugar, salt, me...</td>\n",
       "      <td>[fish, would, survive, salt, water]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  [step, step, guide, invest, share, market, india]   \n",
       "1   1     3     4              [story, kohinoor, koh, noor, diamond]   \n",
       "2   2     5     6  [increase, speed, internet, connection, using,...   \n",
       "3   3     7     8                          [mentally, lonely, solve]   \n",
       "4   4     9    10  [one, dissolve, water, quikly, sugar, salt, me...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0         [step, step, guide, invest, share, market]             0  \n",
       "1  [would, happen, indian, government, stole, koh...             0  \n",
       "2         [internet, speed, increased, hacking, dns]             0  \n",
       "3             [find, remainder, math, math, divided]             0  \n",
       "4                [fish, would, survive, salt, water]             0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I save the `preprocessed_data` as pickle file so that I can just load it and reuse it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: Saving the dataframe as a pickle file acquires less space on the disk as well as keeps the format intact when reloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_preprocessed.pickle', 'wb') as sub_data:\n",
    "    pickle.dump(data, sub_data, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_preprocessed.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After I preprocessed the sentences into list of words, next I assigned each unique word in the whole corpuse a number, so that I could pass this as an input to the model and also create a word2vec representation of these vocabularies (numbers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For doing this, I initialised a dictionary of variable `vocabulary()` which stored each word as a key and a number as a value respectively. Another variable called `inverse_vocabulary()` which is a list that holds the value or number for each unique word. It was initialised which an `<unk>` token since we want to zero pad the words with a number zero I did not want to assign any word a number 0. Hence, initialised with a `<unk>` token which holds the value zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to above, I again iterate over the dataframe using `iterrows()` function, for each question in a row I iterate over all the words one by one. First I check whether the word is already in the dictionary `vocabulary()` if the word is not there then a value based on the length of the `inverse_vocabulary` is assigned to that new word (key), the inverse_vocabulary is updated with the new value along with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To update the dataframe `data` with numbers, I have a list named `sentence_to_numbers` which will append a value (number) for each word. Then using `at()` function the dataframe for each question of the particular row was updated with the list of word indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = dict()\n",
    "inverse_vocabulary = ['<unk>']  \n",
    "\n",
    "for indices, record in data.iterrows():\n",
    "         for column in columns:\n",
    "\n",
    "            sentence_to_numbers = []  \n",
    "            for word in record[column]:\n",
    "\n",
    "               \n",
    "                if word not in vocabulary:\n",
    "                    vocabulary[word] = len(inverse_vocabulary)\n",
    "                    sentence_to_numbers.append(len(inverse_vocabulary))\n",
    "                    inverse_vocabulary.append(word)\n",
    "                else:\n",
    "                    sentence_to_numbers.append(vocabulary[word])\n",
    "\n",
    "            data.at[indices, column] =  sentence_to_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I will save the `data_to_number` representation in a pickle file, so that I can reuse it and save time for later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_number_representation.pickle', 'wb') as sub_data:\n",
    "    pickle.dump(data, sub_data, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will load it as `modified_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_number_representation.pickle', 'rb') as handle:\n",
    "    data = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[1, 1, 2, 3, 4, 5, 6]</td>\n",
       "      <td>[1, 1, 2, 3, 4, 5]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>[7, 8, 9, 10, 11]</td>\n",
       "      <td>[12, 13, 14, 15, 16, 8, 9, 10, 11, 17]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>[18, 19, 20, 21, 22, 23]</td>\n",
       "      <td>[20, 19, 24, 25, 26]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>[27, 28, 29]</td>\n",
       "      <td>[30, 31, 32, 32, 33]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>[34, 35, 36, 37, 38, 39, 40, 41, 42, 43]</td>\n",
       "      <td>[44, 12, 45, 39, 36]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                 question1  \\\n",
       "0   0     1     2                     [1, 1, 2, 3, 4, 5, 6]   \n",
       "1   1     3     4                         [7, 8, 9, 10, 11]   \n",
       "2   2     5     6                  [18, 19, 20, 21, 22, 23]   \n",
       "3   3     7     8                              [27, 28, 29]   \n",
       "4   4     9    10  [34, 35, 36, 37, 38, 39, 40, 41, 42, 43]   \n",
       "\n",
       "                                question2  is_duplicate  \n",
       "0                      [1, 1, 2, 3, 4, 5]             0  \n",
       "1  [12, 13, 14, 15, 16, 8, 9, 10, 11, 17]             0  \n",
       "2                    [20, 19, 24, 25, 26]             0  \n",
       "3                    [30, 31, 32, 32, 33]             0  \n",
       "4                    [44, 12, 45, 39, 36]             0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also saved the `vocabulary` and `inverse_vocabulary` variable in a pickle file, since we would need them while creating the embedding matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocabulary.pickle', 'wb') as vocab:\n",
    "    pickle.dump(vocabulary, vocab, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('inverse_vocab.pickle', 'wb') as inverse_vocab:\n",
    "    pickle.dump(inverse_vocabulary, inverse_vocab, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vocabulary.pickle', 'rb') as handle:\n",
    "    vocabulary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I created the embedding matrix for my vocabulary. For which I used `gensim` library and google's pre-trained word2vec model. Google's pre-trained word2vec model gives a 300 dimensional vector for each word which will be fed to the `Embedding layer` of my model. Since, I will pad my sentences with a zero, I initialise the embedding matrix's zeroth element as zero. The size of the embedding matrix will be `(Size of Vocabulary + 1 (for zero) X 300 (embedding dim))`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I iterated over vocabulary and for each word corresponding to its index I store the 300 dimensional vector in the `embeddings` numpy array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the word is not there in the Google's pretrained model then that word will be randomly initialised, since the `embeddings` array is initialised randomly beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin',binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300\n",
    "embeddings = 1 * np.random.randn(len(vocabulary) + 1, embedding_dim)  # Initialising the embedding matrix randomly\n",
    "embeddings[0] = 0  \n",
    "# Build the embedding matrix\n",
    "for word, index in vocabulary.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embeddings[index] = word2vec.word_vec(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(79602, 300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape #since there are 85158 words in the dataset and 0 is <unk> token which will be a zero padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I stored the embedding matrix as a pickle file too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embeddings.pickle', 'wb') as embed:\n",
    "    pickle.dump(embeddings, embed, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I imported all the Model related libraries that I used for splitting the data, padding the sentences to equal length, keras conv, merge, dropout, maxpooling etc. layers and the Model (Funtional API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Flatten, Conv1D, MaxPooling1D, Embedding,concatenate, Dropout, GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prepare my data for feeding it into the model, I will first split the data into training and validation data. Validation data will help me to tune my hyperparameters, change the architecture, optimizer. It will also tell me whether my Model is `overfitting` on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this I define a new dataframe `new_data` which has only two columns namely `question1` and `question2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = data['is_duplicate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the input to my model will be a fixed size input it is important to keep all the sentences/sequences of same length. For that, I pad all the sentences with zeros based on the length of the sentence that has the maximum words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = max(new_data.question1.map(lambda x: len(x)).max(),new_data.question2.map(lambda x: len(x)).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take `random_state=13` which will divide the training and validation data in the same fashion no matter how many times I run it. If I change the `random_state` the manner in which data is divided will also change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(new_data,labels,random_state=13, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, my network will have two inputs, the data was divided as `question1` and `question2` in a dictionary fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = {'question1': X_train.question1, 'question2': X_train.question2}\n",
    "val = {'question1': X_validation.question1, 'question2': X_validation.question2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, using `itertools()` function on both training and validation data, I padded each sentence with zeros to make each sequence of same size i.e. `103`. By default, Keras will pad zeros in a `pre-order` i.e. before the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset, side in itertools.product([train, val], ['question1', 'question2']):\n",
    "    dataset[side] = pad_sequences(dataset[side], maxlen=max_seq_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I printed the shape of training and validation data for both `question1` and `question2` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((323429, 97), (323429, 97))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['question1'].shape,train['question2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80858, 97), (80858, 97))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val['question1'].shape,val['question2'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use a `Siamese` based architecture. Since the data is distributed in such a fashion wherein there are two questions and we have to find similarity between them, so using siamese is good way to go about this problem statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I import few more modules like `LSTM`, `BatchNormalization` etc. for various experiments that I did. I also imported `earlystopping`, `modelcheckpoint` and `reducelronplateau` which will stop the model if the `validation_loss` will stop decreasing after a certain point, saving best weights in the complete training again based on `validation_loss` and finally decay the `learning_rate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Lambda,Dropout,merge,Lambda,Reshape\n",
    "from keras.layers import BatchNormalization, Bidirectional, GlobalMaxPool1D\n",
    "import keras.backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "import numpy.random as rng\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras import models\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used batch_size of 64, number of training epochs were 25 and weights were initialised using Xavier uniform initialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 \n",
    "n_epoch = 15\n",
    "W_init = keras.initializers.glorot_uniform(seed=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried many architectures out of which I finalised the below architecture. I achieved `~81%` accuracy on the validation data and on training data I achieved `~100%` accuracy. The model definitely overfits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I use Keras Functional API, I defined three functions namely `embedding()`, `middle()` and `predict()`. The embedding function took embedding matrix as an input and was Trainable as True when the network was getting trained. The embedding output is feeded into the middle function module as input on which the maxpooling, lstm and dense layers are applied. The dense layer outputs a 128 feature maps which are then passed to the predict function which computes an L1 distance on these feature maps and then using a Dense layer with one neuron outputs a prediction of 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "call() got an unexpected keyword argument 'output_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-6adc458d16a4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mencoded_q1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmiddle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_question1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mencoded_q2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmiddle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_question2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_q1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoded_q2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mquora\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mquestion1_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquestion2_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-96-6adc458d16a4>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(encoded_q1, encoded_q2)\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m#both = merge([encoded_q1,encoded_q2], mode = L1_distance, output_shape=lambda x: x[0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mmultiply_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mboth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultiply_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoded_q1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoded_q2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mW_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mboth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m                     not base_layer_utils.is_in_eager_or_tf_function()):\n\u001b[0;32m    921\u001b[0m                   \u001b[1;32mwith\u001b[0m \u001b[0mauto_control_deps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutomaticControlDependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 922\u001b[1;33m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    923\u001b[0m                     \u001b[1;31m# Wrap Tensors in `outputs` in `tf.identity` to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m                     \u001b[1;31m# circular dependencies.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: call() got an unexpected keyword argument 'output_shape'"
     ]
    }
   ],
   "source": [
    "question1_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "question2_input = Input(shape=(max_seq_length,), dtype='int32')\n",
    "\n",
    "\n",
    "def embedding():\n",
    "    \n",
    "    embedding_layer = Embedding(len(embeddings), 300, weights=[embeddings], input_length=max_seq_length, trainable=False)\n",
    "    encoded_question1 = embedding_layer(question1_input)\n",
    "    encoded_question2 = embedding_layer(question2_input)\n",
    "    return encoded_question1,encoded_question2\n",
    "\n",
    "def middle(q): \n",
    "    x = MaxPooling1D(10,padding='same')(q)\n",
    "    x = LSTM(200, return_sequences=False,kernel_initializer=W_init)(x)\n",
    "    x = Dense(128, activation=\"relu\",kernel_initializer=W_init)(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def predict(encoded_q1,encoded_q2):\n",
    "# Calculates the distance\n",
    "    \n",
    "    L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "    #both = merge([encoded_q1,encoded_q2], mode = L1_distance, output_shape=lambda x: x[0])\n",
    "    multiply_layer = keras.layers.Multiply()\n",
    "    both = multiply_layer([encoded_q1,encoded_q2])\n",
    "    prediction = Dense(1,activation='sigmoid',kernel_initializer=W_init)(both)\n",
    "    return prediction\n",
    "\n",
    "\n",
    "\n",
    "encoded_question1,encoded_question2 = embedding()\n",
    "encoded_q1 = middle(encoded_question1)\n",
    "encoded_q2 = middle(encoded_question2)\n",
    "prediction = predict(encoded_q1,encoded_q2)\n",
    "    \n",
    "quora = Model([question1_input, question2_input], [prediction])\n",
    "\n",
    "optimizer = Adam(lr=0.001,decay=0.0)\n",
    "\n",
    "quora.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "quora.summary()\n",
    "\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=20, verbose=0,mode='auto')\n",
    "ckpt = ModelCheckpoint(filepath='quora_lstm_max10.h5', save_best_only=True,monitor='val_accuracy', mode='auto')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1,patience=7, verbose=1, epsilon=1e-4,mode='auto')\n",
    "\n",
    "quora_trained = quora.fit([train['question1'], train['question2']], Y_train, batch_size=batch_size, epochs=n_epoch,\n",
    "                            callbacks=[earlyStopping, ckpt, reduce_lr_loss],\n",
    "                            validation_data=([val['question1'], val['question2']], Y_validation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking the network to extract output of 128 feature maps from the middle( ) function by creating a new model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I load the model again which has both weights and model, then just save the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora = models.load_model('quora_lstm_max10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora.save_weights('quora_lstm_max10_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I created a new model which takes two inputs and outputs two outputs, for each of the two questions it will output a feature map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora1 = Model([question1_input, question1_input], [encoded_q1,encoded_q2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I saved the combined model & weights and just weights file for this new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-c1acc09fcd85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mquora1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'quora_lstm_max10_dense.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \"\"\"\n\u001b[0;32m   1051\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[1;32m-> 1052\u001b[1;33m                     signatures, options)\n\u001b[0m\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1054\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[0;32m    126\u001b[0m         not isinstance(model, sequential.Sequential)):\n\u001b[0;32m    127\u001b[0m       raise NotImplementedError(\n\u001b[1;32m--> 128\u001b[1;33m           \u001b[1;34m'Saving the model to HDF5 format requires the model to be a '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m           \u001b[1;34m'Functional model or a Sequential model. It does not work for '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m           \u001b[1;34m'subclassed models, because such models are defined via the body of '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
     ]
    }
   ],
   "source": [
    "quora1.save('quora_lstm_max10_dense.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "quora1.save_weights('quora_lstm_max10_dense_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in user code:\n\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1122 predict_step  **\n        return self(x, training=False)\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:714 call\n        raise NotImplementedError('When subclassing the `Model` class, you should'\n\n    NotImplementedError: When subclassing the `Model` class, you should implement a `call` method.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-aa20e03d90be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_prediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquora1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'question2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#training predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m     87\u001b[0m           method.__name__))\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1266\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1268\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1269\u001b[0m             \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1270\u001b[0m             \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    625\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 506\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    507\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2445\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2446\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2447\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2777\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2779\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2667\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: in user code:\n\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1147 predict_function  *\n        outputs = self.distribute_strategy.run(\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1122 predict_step  **\n        return self(x, training=False)\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:927 __call__\n        outputs = call_fn(cast_inputs, *args, **kwargs)\n    C:\\Users\\pasin\\.conda\\envs\\Panchakarama\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py:714 call\n        raise NotImplementedError('When subclassing the `Model` class, you should'\n\n    NotImplementedError: When subclassing the `Model` class, you should implement a `call` method.\n"
     ]
    }
   ],
   "source": [
    "train_prediction = quora1.predict([train['question1'],train['question2']]) #training predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prediction = np.array(train_prediction) #converting the list of predictions into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 323429, 128)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the predictions as a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('train_predictions.npy',train_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the output of `train_prediction` returns two predictions for `question1` and `question2`. I now reshape it to a one output which will have a shape `(2 X 323429,128)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = np.reshape(train_prediction,(-1,128)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646858, 128)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation data predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prediction = quora1.predict([val['question1'],val['question2']]) #valid predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prediction = np.array(val_prediction) #converting the list of predictions into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 80858, 128)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('val_predictions.npy',val_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred = np.reshape(val_prediction,(-1,128)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161716, 128)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I use the `original_data` that I had defined in the starting and will append the `question2` with `question1` to make it one single column of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(original_data,original_data.is_duplicate, random_state=13,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train.question1.append(X_train.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns = ['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646858, 1)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = X_validation.question1.append(X_validation.question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = val_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = val_data.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.columns = ['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161716, 1)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** I use 400K questions against which a query question will be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, I divide the `train_pred` into two 400k and after 400K take 2K predictions as a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646858, 128)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_pred = val_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161716, 128)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_questions = val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161716, 1)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_questions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_questions = train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646858, 1)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_questions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brute-Force Method for Finding the Top-3 Closest from the Training data for a given Input Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_array = np.zeros((100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def comparison(query):\n",
    "    arr = []\n",
    "    for i in range(data_pred.shape[0]):\n",
    "            predict = np.linalg.norm(query - data_pred[i])\n",
    "            arr.append(predict)\n",
    "    hp = np.array(heapq.nsmallest(3, range(len(arr)), arr.__getitem__))\n",
    "    return hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I took only 100 query questions since this method takes 313 seconds to output top-3 suggestions for each input query time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313.1226750000005\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.clock()\n",
    "for i in range(100):\n",
    "    main_array[i,:] = comparison(query_pred[i])\n",
    "print (time.clock() - start)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 3)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_array = main_array.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "filename = 'output_brute_force.csv'\n",
    "a = open(filename, 'a')\n",
    "\n",
    "headers = ['Query', 'Closest-1','Closest-2','Closest-3']\n",
    "writer = csv.DictWriter(a, delimiter='\\t', lineterminator='\\n',fieldnames=headers)\n",
    "fileEmpty = os.stat(filename).st_size == 0\n",
    "writer.writeheader()\n",
    "for i in range(len(main_array)):\n",
    "    a.write((str(query_questions.iloc[i])).split('\\n')[0].split('    ')[1]+'\\t'+str(data_questions.iloc[main_array[i][0]]).split('\\n')[0].split('    ')[1] +'\\t'+ str(data_questions.iloc[main_array[i][1]]).split('\\n')[0].split('    ')[1] +'\\t'+ str(data_questions.iloc[main_array[i][2]]).split('\\n')[0].split('    ')[1] + \"\\n\")\n",
    "a.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brute = pd.read_csv('output_brute_force.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Closest-1</th>\n",
       "      <th>Closest-2</th>\n",
       "      <th>Closest-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Donald Trump in league with Putin?</td>\n",
       "      <td>Is Donald Trump in league with Putin?</td>\n",
       "      <td>Is Donald Trump in league with Putin?</td>\n",
       "      <td>What are some ways to contact Jesse Ventura?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does Bootstrap do?</td>\n",
       "      <td>What is Kairos like?</td>\n",
       "      <td>What is frugal?</td>\n",
       "      <td>What's so special about Grana?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
       "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
       "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
       "      <td>Technology: Are we compromising on wisdom over information?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Query  \\\n",
       "0  What are the things that we can do to bring change in Indian education system?   \n",
       "1  Is Donald Trump in league with Putin?                                            \n",
       "2  What does Bootstrap do?                                                          \n",
       "3  Why did Sanskrit fail to become a suitable language for computers?               \n",
       "4  How can I increase my typing speed fast?                                         \n",
       "\n",
       "                                                                        Closest-1  \\\n",
       "0  What are the things that we can do to bring change in Indian education system?   \n",
       "1  Is Donald Trump in league with Putin?                                            \n",
       "2  What is Kairos like?                                                             \n",
       "3  Why did Sanskrit fail to become a suitable language for computers?               \n",
       "4  How can I increase my typing speed fast?                                         \n",
       "\n",
       "                                                                        Closest-2  \\\n",
       "0  What are the things that we can do to bring change in Indian education system?   \n",
       "1  Is Donald Trump in league with Putin?                                            \n",
       "2  What is frugal?                                                                  \n",
       "3  Why did Sanskrit fail to become a suitable language for computers?               \n",
       "4  How can I increase my typing speed fast?                                         \n",
       "\n",
       "                                                                        Closest-3  \n",
       "0  What are the things that we can do to bring change in Indian education system?  \n",
       "1  What are some ways to contact Jesse Ventura?                                    \n",
       "2  What's so special about Grana?                                                  \n",
       "3  Technology: Are we compromising on wisdom over information?                     \n",
       "4  How can I increase my typing speed fast?                                        "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_brute.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Top-3 Closest from the Training data for a given Input Query using KMeans Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the search space faster, I used KMeans clustering. Firstly, I trained Kmeans on the training data to get the cluster centers then predicted a cluster center for every new query. This improved the performance massively. Comparing to the brute-force method, Kmeans gave me top-3 results within `200secs` that too when I had not 100 but 1000 query questions against 650K questions and without any performance loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=20, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_fit = kmeans.fit(data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19,  7, 16, ..., 17, 15, 14], dtype=int32)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_fit.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 128)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_data_pred = kmeans.predict(data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(646858,)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans_data_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kmeans_model.pickle', 'wb') as f:\n",
    "     pickle.dump(kmeans_fit, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    index = np.where(kmeans_data_pred == i)\n",
    "    np.array(cluster_centers[i]).dump(open('clusters/cluster_center[%s].npy' % i, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.zeros((1000,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(cluster,j):\n",
    "    #print (cluster)\n",
    "    assign = dict()\n",
    "    a = np.where(kmeans_data_pred == cluster)[0]\n",
    "    for i in a:\n",
    "        dist = np.linalg.norm(query_pred[j] - data_pred[i])\n",
    "        assign[i] = dist\n",
    "    sorted_by_value = sorted(assign.items(), key=lambda kv: kv[1])\n",
    "    a = [i for i, v in (sorted_by_value)]\n",
    "    return (a[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201.52732800000013\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.clock()\n",
    "for i in range(1000):\n",
    "    array[i,:] = compare(kmeans.predict(query_pred[i].reshape(-1,128)),i)\n",
    "print (time.clock() - start)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = array.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "filename = 'output_kmeans.csv'\n",
    "a = open(filename, 'w')\n",
    "\n",
    "headers = ['Query', 'Closest-1','Closest-2','Closest-3']\n",
    "writer = csv.DictWriter(a, delimiter='\\t', lineterminator='\\n',fieldnames=headers)\n",
    "fileEmpty = os.stat(filename).st_size == 0\n",
    "writer.writeheader()\n",
    "\n",
    "for i in range(len(array)):\n",
    "    a.write((str(query_questions.iloc[i])).split('\\n')[0].split('    ')[1] + '\\t' + str(data_questions.iloc[array[i][0]]).split('\\n')[0].split('    ')[1] + '\\t' + str(data_questions.iloc[array[i][1]]).split('\\n')[0].split('    ')[1] + '\\t' + str(data_questions.iloc[array[i][2]]).split('\\n')[0].split('    ')[1] + \"\\n\")\n",
    "a.close()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_kmeans = pd.read_csv('output_kmeans.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Closest-1</th>\n",
       "      <th>Closest-2</th>\n",
       "      <th>Closest-3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "      <td>What are the things that we can do to bring change in Indian education system?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is Donald Trump in league with Putin?</td>\n",
       "      <td>Is Donald Trump in league with Putin?</td>\n",
       "      <td>Is Donald Trump in league with Putin?</td>\n",
       "      <td>What are some ways to contact Jesse Ventura?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What does Bootstrap do?</td>\n",
       "      <td>What is Kairos like?</td>\n",
       "      <td>What is frugal?</td>\n",
       "      <td>What is a Discord chat?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
       "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
       "      <td>Why did Sanskrit fail to become a suitable language for computers?</td>\n",
       "      <td>Technology: Are we compromising on wisdom over information?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "      <td>How can I increase my typing speed fast?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Query  \\\n",
       "0  What are the things that we can do to bring change in Indian education system?   \n",
       "1  Is Donald Trump in league with Putin?                                            \n",
       "2  What does Bootstrap do?                                                          \n",
       "3  Why did Sanskrit fail to become a suitable language for computers?               \n",
       "4  How can I increase my typing speed fast?                                         \n",
       "\n",
       "                                                                        Closest-1  \\\n",
       "0  What are the things that we can do to bring change in Indian education system?   \n",
       "1  Is Donald Trump in league with Putin?                                            \n",
       "2  What is Kairos like?                                                             \n",
       "3  Why did Sanskrit fail to become a suitable language for computers?               \n",
       "4  How can I increase my typing speed fast?                                         \n",
       "\n",
       "                                                                        Closest-2  \\\n",
       "0  What are the things that we can do to bring change in Indian education system?   \n",
       "1  Is Donald Trump in league with Putin?                                            \n",
       "2  What is frugal?                                                                  \n",
       "3  Why did Sanskrit fail to become a suitable language for computers?               \n",
       "4  How can I increase my typing speed fast?                                         \n",
       "\n",
       "                                                                        Closest-3  \n",
       "0  What are the things that we can do to bring change in Indian education system?  \n",
       "1  What are some ways to contact Jesse Ventura?                                    \n",
       "2  What is a Discord chat?                                                         \n",
       "3  Technology: Are we compromising on wisdom over information?                     \n",
       "4  How can I increase my typing speed fast?                                        "
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_kmeans.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
